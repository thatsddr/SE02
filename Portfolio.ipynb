{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "major-transparency",
   "metadata": {},
   "source": [
    "# SE_02 Portfolio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "married-france",
   "metadata": {},
   "source": [
    "Created By: Domenico Di Ruocco"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alone-communist",
   "metadata": {},
   "source": [
    "# Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conscious-manitoba",
   "metadata": {},
   "source": [
    "- [Introduction to Theory](#introductionT)\n",
    "    - [Time Complexity](#timeComplexity)\n",
    "    - [Space Complexity](#spaceComplexity)\n",
    "    - [Asymptotic Notation](#asymptoticNotation)\n",
    "        - [Big O](#bigO)\n",
    "        - [Big Ω](#bigOmega)\n",
    "        - [Big Θ](#bigTheta)\n",
    "        - [Working with the Asymptotic Notation](#workingWithNotation)\n",
    "    - [Order of Dominance in the Asymptotic Limit](#orderOfDominance)\n",
    "- [Introduction to Data Structures](#introductionDS)\n",
    "    - [Arrays](#arrays)\n",
    "    - [Linked Lists](#linkedLists)\n",
    "    - [Stacks](#stacks)\n",
    "    - [Queues](#queues)\n",
    "    - [Hash Tables](#hashTables)\n",
    "    - [Trees](#trees)\n",
    "        - [Binary Trees](#binaryTrees)\n",
    "            - [Binary Search Trees](#binarySearchTrees)\n",
    "            - [Red Black Trees](#redBlackTrees)\n",
    "            - [Ropes](#ropes)\n",
    "        - [Heaps](#heaps)\n",
    "    - [Graphs](#graphs)\n",
    "- [Sources](#sources)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "buried-consultancy",
   "metadata": {},
   "source": [
    "<div id=\"introductionT\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "commercial-preservation",
   "metadata": {},
   "source": [
    "# Introduction To Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "educational-exploration",
   "metadata": {},
   "source": [
    "In Computer Science, an algorithm is a set of instructions that must be followed in a fixed order to calculate an answer to a mathematical problem. Since it is common to find more than one algorithm that has been developed to solve the same problem, we need a way to analyze and compare them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "special-black",
   "metadata": {},
   "source": [
    "<div id=\"timeComplexity\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "looking-blank",
   "metadata": {},
   "source": [
    "## Time Complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "industrial-consumer",
   "metadata": {},
   "source": [
    "One way to compare two algorithms that solve the same problem, assuming that the solutions provided by both are correct, is to compare the time it takes each of them to get to the solution. The problem with this method is that it depends on the hardware were the algorithm runs. It is for this reason that for machine-independent algorithm design we consider our algorithm to be running on a hypothetical machine called the \"Random Access Machine\" or RAM.\n",
    "\n",
    "On the RAM, we consider each simple operation (+, *, -, =, if, call) and each memory access to take one time step, while loops and subroutines are considered to be the composition of many single-step operation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "missing-player",
   "metadata": {},
   "source": [
    "<div id=\"spaceComplexity\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alleged-manufacturer",
   "metadata": {},
   "source": [
    "## Space Complexity\n",
    "Another way to compare two algorithms is to compare the total space it takes them get to the solution. The total space includes the size of the input and auxiliary space, which is the extra or temporary space used by the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "violent-disney",
   "metadata": {},
   "source": [
    "<div id=\"asymptoticNotation\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conceptual-karma",
   "metadata": {},
   "source": [
    "## Asymptotic Notation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ignored-reducing",
   "metadata": {},
   "source": [
    "We can use the RAM model to determine the number of steps it will take an algorithm to end with an input we choose, but estimating the worst, average, and best case runtime scenerio with the RAM model can be unconvenint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "animated-carroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "def even_numbers_avg(array):\n",
    "    '''\n",
    "    This function returns either the average of the sum of even numbers,\n",
    "    or None.\n",
    "    '''\n",
    "    even_sum = 0                    #1 time step\n",
    "    even_count = 0                  #1 time step\n",
    "                                    #n times:\n",
    "    for n in array:                    #1 time step\n",
    "        if n % 2 == 0:                 #1 time step\n",
    "            even_sum += n                  #1 time step\n",
    "            even_count +=1                 #1 time step\n",
    "            \n",
    "    if even_count > 0:              #1 time step\n",
    "        return even_sum/even_count     #1 time step\n",
    "    else:                           #1 time step\n",
    "        return None                    #1 time step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classified-royalty",
   "metadata": {},
   "source": [
    "In the example above, we can try to generalize the time complexity of this algorithm by counting every step, and we will find that in the worst case its time complexity will be: $T(n) = 5n + 6$. Its space complexity will be the size of the array n, plus the two variables we initialize."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civil-custody",
   "metadata": {},
   "source": [
    "The problem with the notation we used above is that is difficult to work precisely with it. In the example above we can see that both return statements have been counted as well as every step in the for loop, which is correct for the worst but not for the average and best case scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excited-stability",
   "metadata": {},
   "source": [
    "Since we can approximate an algorithm to a mathematical function, we can also determine its growth as a function of the input and define an upper bound function (Big O), a lower bound function (Big Ω), or both (Big Θ) in order to understand how it grows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fancy-april",
   "metadata": {},
   "source": [
    "In Asymptotic Notation, we only consider the fastest growing term without any multiplicative constant. E.g.: in the example above $T(n) = 5n + 6$ is O(n) and not O(5n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modern-jackson",
   "metadata": {},
   "source": [
    "<div id=\"bigO\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usual-marsh",
   "metadata": {},
   "source": [
    "### Big O"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "african-reservoir",
   "metadata": {},
   "source": [
    "The Big O of a function is its asymptotic upper bound. This means that the running time of a function $T$ will be always shorter than that of $f$. To generalize we can say that a funciton $T(n)$ is $O(f(n))$ if there is a constant $k$ such that $T(n) < k·f(n)$ for large enough $n$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intended-picking",
   "metadata": {},
   "source": [
    "<img src=\"pics/Big O.png\" alt=\"Big O\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleared-fever",
   "metadata": {},
   "source": [
    "<div id=\"bigOmega\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "voluntary-muslim",
   "metadata": {},
   "source": [
    "### Big Ω"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "damaged-patient",
   "metadata": {},
   "source": [
    "The Big Ω of a function is its asymptotic lower bound. This means that the running time of a function $T$ will always be longer than that of $f$. To generalize we can say that a funciton $T(n)$ is $Ω(f(n))$ if there is a constant $k$ such that $T(n) > k·f(n)$ for large enough $n$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "religious-singles",
   "metadata": {},
   "source": [
    "<img src=\"pics/Big Omega.png\" alt=\"Big Omega\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specialized-knowing",
   "metadata": {},
   "source": [
    "<div id=\"bigTheta\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "passing-brick",
   "metadata": {},
   "source": [
    "### Big Θ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overall-lesson",
   "metadata": {},
   "source": [
    "The Big Θ of a function is its asymptotic tight bound. This Means that the funciton always runs in a time comprised between the run time of the two asymptotic bounds. To generalize we can say that a funciton $T(n)$ is $Θ(f(n))$ if there are two constants $k_{1} and k_{2}$\n",
    "such that $T(n) ≥ k_{1}·f(n)$ and $T(n) ≤ k_{2}·f(n)$ for large enough $n$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "south-genesis",
   "metadata": {},
   "source": [
    "<img src=\"pics/Big Theta.png\" alt=\"Big Theta\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "armed-conclusion",
   "metadata": {},
   "source": [
    "<div id=\"workingWithNotation\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approximate-development",
   "metadata": {},
   "source": [
    "### Working with the Asymptotic Notation\n",
    "\n",
    "1. Addition\n",
    "\n",
    "    We can sum two functions together and the result will be the dominant one:\n",
    "    $f(n) + g(n) = Θ(max(f(n), g(n)))$\n",
    "2. Multiplication\n",
    "\n",
    "    Multiplying a function by a constant will result in the constant to be ignored. If instead we are multiplying two functions, we proceed as follows: $Θ(f(n))·Θ(g(n)) = Θ(f(n)·g(n))$\n",
    "    \n",
    "\n",
    "**The same rules also apply to Big O and Big Ω**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boxed-essence",
   "metadata": {},
   "source": [
    "<div id=\"orderOfDominance\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "martial-worse",
   "metadata": {},
   "source": [
    "## Order of Dominance in the Asymptotic Limit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bridal-sunday",
   "metadata": {},
   "source": [
    "Let's consider some common asymptotic growths, valid for both space and time complexity:\n",
    "- Constant: $O(1)$\n",
    "- Logarithmic: $O(log(n))$\n",
    "- Linear: $O(n)$\n",
    "- Quasilinear: $O(n·log(n))$\n",
    "- Quadratic: $O(n^{2})$\n",
    "- Exponential: $O(2^{n})$\n",
    "- Factorial: $O(n!)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vanilla-hello",
   "metadata": {},
   "source": [
    "To understand the difference between some of the most common time complexities, take a look at thi graph below, were the x-axys represents the size of the input of the functions and the y-axys represents the result of the functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agreed-thumbnail",
   "metadata": {},
   "source": [
    "<img src=\"pics/Comparison.png\" alt=\"Functions Compared\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plastic-cardiff",
   "metadata": {},
   "source": [
    "We can see that the dominance order of these functions is: $$n! >> 2^n >> n^2 >> n·logn >> n >> log(n) >> 1$$\n",
    "\n",
    "It is also clear that an efficient algorithm can really make the difference in terms of time and space efficiency, especially as the input size grows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "backed-module",
   "metadata": {},
   "source": [
    "<div id=\"introductionDS\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crazy-summer",
   "metadata": {},
   "source": [
    "# Introduction to Data Structures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accredited-contrast",
   "metadata": {},
   "source": [
    "Data Structures are constructs that allow you to store and manage data values and provide you with methods to access or manipulate such data. There are different kinds of data structures available, each with its pros and cons. It is important to understand the strengths and weaknesses of different Data Structures in order to choose the right one for your use case and make your software more efficient.\n",
    "\n",
    "Data structures can be classified in \"contiguos\" and \"linked\". The former are based upon arrays and the latter on pointers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggressive-portable",
   "metadata": {},
   "source": [
    "<div id=\"arrays\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minus-poster",
   "metadata": {},
   "source": [
    "## Arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amber-virginia",
   "metadata": {
    "tags": []
   },
   "source": [
    "An Array is an example of contiguos data structure. They are collections of data of fixed size allocated in contiguos memory locations, which make accessing the data values by index really efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innovative-airfare",
   "metadata": {},
   "source": [
    "<figure>\n",
    "    <img src=\"pics/Array.png\" alt=\"Example of array in memory\" width=\"450\"/>\n",
    "    <figcaption>\n",
    "        Image source: <a href=\"https://www.geeksforgeeks.org/array-data-structure\">Geeks for Geeks</a>\n",
    "    </figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunrise-million",
   "metadata": {},
   "source": [
    "Analysis of common operations on arrays:\n",
    "\n",
    "- Access:\n",
    "\n",
    "    Since the values are indexed and this is a data structure contiguos in memory it is possible to access data in the array with a worst-case time complexity of $O(1)$ (constant time complexity);\n",
    "- Search:\n",
    "\n",
    "    The data stored in an array is not always sorted, so we need to assume that every memory slot could be searched before finding the element we are looking for, therefore the time complexity of this operation is $O(n)$ (linear time complexity);\n",
    "- Insertion:\n",
    "\n",
    "    To insert an element at a specific index we might, in the worst case scenerio, need to shift all the other elements in the array, so the time complexity for this operation will be $O(n)$;\n",
    "- Deletion:\n",
    "\n",
    "    To delete an element in an array we may run into the same issue of insertion, hence the time complexity will be, again, $O(n)$.\n",
    "\n",
    "The space efficiency of arrays is also one of its major strengths, since arrays are only made up of pure data, no space is wasted.\n",
    "\n",
    "Another advantage of arrays is their memory locality, which takes full advantage of the speed of cahce memory.\n",
    "\n",
    "Their main disadvantage is the impossibility of changing their size while the program is running. It is however possible to avoid this limitation using dynamic arrays, arrays whose size doubles every time they are full.\n",
    "\n",
    "Arrays can be used for nearly everything, and other data structures are based on them as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decreased-appraisal",
   "metadata": {},
   "source": [
    "<div id=\"linkedLists\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flying-condition",
   "metadata": {},
   "source": [
    "## Linked Lists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "square-drilling",
   "metadata": {},
   "source": [
    "Linked lists are an example of linked data structures. They are collections of data not allocated in contiguos memory locations but in which the elements are linked using a pointer to the next value in the case of a Singly Linked List or to both the previous and the next in the case of a Doubly Linked List.\n",
    "Linked lists are made up of a \"Nodes\", the first one of which is called Head. Every node has a pointer that points to the next node (or to a null value in case it is the last element), while in case they are doubly linked list they also have a pointer to the previous value (or to a null value in case of the first element)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agricultural-overall",
   "metadata": {},
   "source": [
    "<figure>\n",
    "    <img src=\"pics/LinkedList.png\" alt=\"Representation of singly linked lists\" width=\"500\"/>\n",
    "    <figcaption>\n",
    "        Singly Linked List. Image source: <a href=\"https://www.geeksforgeeks.org/data-structures/linked-list/\">Geeks for Geeks</a>\n",
    "    </figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "driving-sustainability",
   "metadata": {},
   "source": [
    "<figure>\n",
    "    <img src=\"pics/DoublyLinkedList.png\" alt=\"Representation of doubly linked lists\" width=\"500\"/>\n",
    "    <figcaption>\n",
    "        Doubly Linked List. Image source: <a href=\"https://www.geeksforgeeks.org/doubly-linked-list/\">Geeks for Geeks</a>\n",
    "    </figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriental-reporter",
   "metadata": {},
   "source": [
    "Analysis of common operations on linked lists:\n",
    "\n",
    "- Access:\n",
    "\n",
    "    Linked Lists (both Singly and Dobly Linked) are not indexed data structures. This mean that we cannot access one value directly, but we need to start from the Head (or also from the last element if we are in a Doubly Linked List) and follow the pointers until we find the element we are looking for or we find a null value. For this reason, the time complexity of this operation is $O(n)$;\n",
    "- Search:\n",
    "\n",
    "    The same concept from the access operation applies here;\n",
    "- Insertion:\n",
    "\n",
    "    To insert a new node \"B\" in a Singly Linked List, between two nodes \"A\" and \"C\", we just need to make sure that the node \"A\" points to node \"B\" and that node \"B\" points to node \"C\". If the list is a Doubly Linked one, we also need to make sure that the backward pointer of node \"C\" and \"B\" is set correctly. \n",
    "    We can also add an element at the beginning of a Linked List by simply making it the new head and set its pointer to the previous head, and in case it is a Doubly Linked List we also need to point the backward pointer of the previous Head to the new Head. The time complexity of this operation, after you know the position where you want to insert a new element is $O(1)$, since you only need to change the value of the pointer(s);\n",
    "- Deletion:\n",
    "\n",
    "    The same concept from the insertion operation applies here, except that insteaf of changing the pointer(s) to include a new element we change them to exclude one. For this reason the time complexity of this operation is also $O(1)$.\n",
    "\n",
    "Linked lists are not really space efficient since they need to store the pointers and the extra space needed will be $O(n)$.\n",
    "\n",
    "As we have seen, their main disadvantages are that they are slow in searching and occupy more memory than arrays. Moreover, another disadvantage is that they don't benefit from the speed of cache memory since they are not stored contiguously.\n",
    "\n",
    "They are used where dynamic memory allocation is required, and just as arrays, other data structures are based on them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recent-omega",
   "metadata": {},
   "source": [
    "<div id=\"stacks\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electoral-narrative",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Stacks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "athletic-coach",
   "metadata": {},
   "source": [
    "A Stack is a linear data structure. They allow two operations: insertion at the top (push) and read and removal at the top (pop). For this reason stacks follow the \"Last In First Out\" or \"LIFO\" order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "passing-bottle",
   "metadata": {},
   "source": [
    "<figure>\n",
    "    <img src=\"pics/Stack.png\" alt=\"Representation of a stack\" width=\"500\"/>\n",
    "    <figcaption>\n",
    "        Stacks. Image source: <a href=\"https://www.geeksforgeeks.org/stack-data-structure/\">Geeks for Geeks</a>\n",
    "    </figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surgical-nerve",
   "metadata": {},
   "source": [
    "Analysis of common operations on Stacks:\n",
    "    \n",
    "- Access:\n",
    "\n",
    "    Access an element in a Stack entails that we need to read and remove the top item until we reach the one we're looking for or we are left with an empty Stack. Because of this, the time complexity of this operation will depend on its size and will therefore be $O(n)$;\n",
    "- Search:\n",
    "\n",
    "    The search operation in a Stack is the same as the access operation.\n",
    "- Insertion:\n",
    "\n",
    "    We can only insert an element at the top of the Stack, and for this reason this operation will have a time complexity of $O(1)$ (constant time);\n",
    "- Deletion:\n",
    "\n",
    "    Just like insertion, we can only delete the top element of a Stack and thus the time complexity of this operation will also be $O(1)$.\n",
    "    \n",
    "\n",
    "Depending on how Stacks are implemented they can be more or less space efficient.\n",
    "\n",
    "Their main advantage is that they are easy to implement and that that the insertion and deletion operations are really time efficient.\n",
    "\n",
    "Uses of Stacks include situations in which the order in which the elements are inserted/deleted is not important, or when you specifically need to retrieve the last elements first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "choice-attraction",
   "metadata": {},
   "source": [
    "<div id=\"queues\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "antique-reply",
   "metadata": {},
   "source": [
    "## Queues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quick-colleague",
   "metadata": {},
   "source": [
    "A Queue is a linear data structure similar to the Stack but that supports a different set of operations, Enqueue (inserting at item at the rear of the queue) and Dequeue (reading and deleting an item from the fron of the queue). Instead of the LIFO, Queues follow the FIFO order (First In, First Out)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "external-imaging",
   "metadata": {},
   "source": [
    "<figure>\n",
    "    <img src=\"pics/Queue.png\" alt=\"Representation of a queue\" width=\"500\"/>\n",
    "    <figcaption>\n",
    "        Queues. Image source: <a href=\"https://www.geeksforgeeks.org/queue-data-structure/\">Geeks for Geeks</a>\n",
    "    </figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offensive-sudan",
   "metadata": {},
   "source": [
    "Analysis of common operations on Queues:\n",
    "    \n",
    "- Access:\n",
    "\n",
    "    Access an element in a Queue is similar to the access operation in a Stack, we need to read and remove (dequeue) the front item until we find the one we are looking for or no elements are left in the Queue. The time complexity of this operation will henve be $O(n)$;\n",
    "- Search:\n",
    "\n",
    "    The search operation in a Queue is the same as the access operation.\n",
    "- Insertion:\n",
    "\n",
    "    We can only insert an element at the rear of the Queue, and for this reason this operation will have a time complexity of $O(1)$ (constant time);\n",
    "- Deletion:\n",
    "\n",
    "    We can only delete the front element of a Queue and thus the time complexity of this operation will also be $O(1)$.\n",
    "\n",
    "The space complexity of stacks also depends on how they are implemented.\n",
    "\n",
    "Just like Stacks they are also easy to implement and that the insertion and deletion operations are really time efficient.\n",
    "\n",
    "Queues are useful in situations in which the order in which the elements are retrieved matters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabulous-thunder",
   "metadata": {},
   "source": [
    "<div id=\"hashTables\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formed-badge",
   "metadata": {},
   "source": [
    "## Hash Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inner-shannon",
   "metadata": {},
   "source": [
    "A Hash Table is data structure in which a key-value data pair is stored. It is usually implemented with an array and it works by hashing (generating an unique value, integer in this case) the key and storing the kay-value data at the index returned by the hash function. In this way, given the key, it is really efficient to locate its value.\n",
    "\n",
    "The main challenge of Hash Tables is to remain memory efficient while avoiding collisions (having 2 or more elements at the same index)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wound-failing",
   "metadata": {},
   "source": [
    "<figure>\n",
    "    <img src=\"pics/HashTable.png\" alt=\"Representation of a hash table\" width=\"400\"/>\n",
    "    <figcaption>\n",
    "        Hash Table. Image source: <a href=\"https://en.wikipedia.org/wiki/Hash_table#/media/File:Hash_table_3_1_1_0_1_0_0_SP.svg/\">Wikipedia</a>\n",
    "    </figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valued-kidney",
   "metadata": {},
   "source": [
    "Analysis of common operations on Hash Tables:\n",
    "\n",
    "- Search / Access:\n",
    "\n",
    "    Since the data stored in a Hash Table is indexed, it will take constant time to search or access it ($O(1)$), even if depending on the hashing algorithm, it could depend on the size of the key. Other edge cases include collision, and we will take such situation into acccount later;\n",
    "\n",
    "- Insertion:\n",
    "\n",
    "    To insert an element in a Hash table, we just need to execute the hash function and insert the data in the array, which happens, depending on the hashing funciton, wither with a time complexity of $O(1)$ (constant time), or with a time complexity dependent on the key size. This can change in case of collisions;\n",
    "- Deletion:\n",
    "\n",
    "    Deleting an element in a Hash Table is a process similar to searching for it, except that insted of reading it, it gets deleted. Normally this process happend with a time complexity of $O(1)$, but also this operation can be slowed down by collisions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clear-locking",
   "metadata": {},
   "source": [
    "**Collisions** are more frequent as the array fills up because the empty slots are less. It is common to use the variable $a=n/m$ (where $n$ is the number of elements and $m$ the length of the array) to measure how full is an array. Once a collision happen there are different ways to deal with it:\n",
    "- Chaining:\n",
    "\n",
    "    We add more than 1 key value pair to the same index. In this way inserting a new element has always a time complexity of $O(1)$ while searching for an element a time complexity of $(O(1+a))$;\n",
    "    \n",
    "- Open Addressing:\n",
    "\n",
    "    We store the elements in same array without using additional data structures. Ways to find a new index include:\n",
    "    \n",
    "    - Linear Probing:\n",
    "\n",
    "        We store the colliding element in the first available slot in the array. This method, however, can be really inefficient. Inserting and searching for an element can have a time complexity of $O(n)$;\n",
    "    - Quadratic Probing:\n",
    "        \n",
    "        We find a new index by adding an arbitrary number that increases quadratically. Just like Linear probing, this method can be really inefficient with inserting and sorting operations that can have a time complexity of $O(n)$;\n",
    "    - Double Hashing:\n",
    "\n",
    "        We generate a new hash if a collision is detected. We can chose between different function to implement this technique, but generally this method is more time efficient compared to the other 2, especially in searching."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "circular-configuration",
   "metadata": {},
   "source": [
    "Hash Table are not really space efficient.\n",
    "\n",
    "Their main advantage is the efficienty with which insert,\n",
    "\n",
    "Common implementations of Hash Tables include python dictionaries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corrected-stability",
   "metadata": {},
   "source": [
    "<div id=\"trees\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "combined-courtesy",
   "metadata": {},
   "source": [
    "## Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polish-oliver",
   "metadata": {},
   "source": [
    "Trees are non linear data structures that can be considered an extension of a linked list. In a Tree, each node points to some \"children\" nodes or a null value, creating an hierarchical data structure.\n",
    "\n",
    "Trees have a lot of properties, understand them we are going to take into consideration the Binary Tree in th eimage below (a Binary Tree is a Tree in which each node has at most 2 children)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intermediate-schedule",
   "metadata": {},
   "source": [
    "<figure>\n",
    "    <img src=\"pics/BinaryTree.png\" alt=\"Representation of a binary tree\" width=\"500\"/>\n",
    "    <figcaption>\n",
    "        Binary Tree. Image source: <a href=\"https://www.geeksforgeeks.org/binary-tree-data-structure//\">GeeksforGeeks</a>\n",
    "    </figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitted-blackberry",
   "metadata": {},
   "source": [
    "**Properties and Terminology of Trees:**\n",
    "\n",
    "- **Node**: an element of the Tree, contains data and pointers to its children;\n",
    "- **Edge**: The \"link\" between 2 nodes, every Tree has a maximum of $N-1$ edges, where $N$ is the number of nodes;\n",
    "- **Parent Node**: the predecessor of a node, or the node that points to another. In the example above, among the others, \"1\" is the parent of \"2\" and \"3\", and \"2\" is the parent of \"4\" and \"5\";\n",
    "- **Child node**: the descendant of a node. In the example above, among the others, \"11\" is a child of \"2\" and \"3\" is a child of \"1\";\n",
    "- **Root Node**: The first element of the Tree and the only node without a parent node, in the example above the node is \"1\";\n",
    "- **Siblings Nodes**: nodes that are children of the same parent node. In the example above, \"4\" and \"5\" and \"8\" and \"9\" are examples of siblings;\n",
    "- **Leaf**: a node without children, like \"11\" or \"14\" in the example above.\n",
    "- **Internal Node**: a node with at least 1 child. \"7\", \"4\" and \"1\" are internal nodes in the example above;\n",
    "- **Degree**: the nummber of children that a node has. In a binary tree, this number is never greater than 2. The \"Degree of Tree\" is the Degree of the node with the highest Degree;\n",
    "- **Level**: the \"distance\" of a Node from the Root Node, starting at 1. In the example above, the level of \"1\" is 1, the degree of \"3\" is 2, the degree of \"5\" is 3 and the degree of \"9\" is 4;\n",
    "- **Height**: is the \"distance\" between the futhest descending leaf and a node, starting at 0 for the leaves. In the example above, the height of \" 10\" is 0, the height of \"4\" is 1, the height of \"3\" is 2 and the Height of \"1\" is \"4\". The Height of the Root Node is also the Height of Tree.\n",
    "- **Depth**: the number of edges between a Node and the Root Node. For example, it is 0 for \"1\" and 2 for \"7\" in the Tree above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opening-crawford",
   "metadata": {},
   "source": [
    "Analysis of common operations on trees:\n",
    "\n",
    "- Access:\n",
    "    \n",
    "    Since a Tree is not an indexed data structure, in the worst case it is possible that we need to look trough all the nodes until we find the one we are looking for. For this reason the time complexity of this operation is $O(n)$;\n",
    "- Search:\n",
    "    \n",
    "    Trees are not ordered data structures, or at least not all of them. For this reason searching in a tree could also mean that we need to search trough all teh other nodes, either with a Depth-First-Search or a Breadth-First-Search approach (we will look at both of these algorithms in the algorithms section of this portfolio) with a time complexity that in both cases is of $O(n)$;\n",
    "- Insertion:\n",
    "    \n",
    "    Inserting a Node in a tree may require changing the positions of the other nodes as well to keep the properties of the tree. For this reason this operation also has a time complexity of $O(n)$;\n",
    "- Deletion:\n",
    "\n",
    "    Deletion, just like insertion, may require to rearrange all the other Nodes and so this operation also happens in $O(n)$ time complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superb-vancouver",
   "metadata": {},
   "source": [
    "<div id=\"binaryTrees\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "global-radius",
   "metadata": {},
   "source": [
    "### Binary Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expected-jonathan",
   "metadata": {},
   "source": [
    "As I mentioned before, a Binary Tree is a Tree in which is node can have a maximum of 2 children, therefore each node cointains some data, a pointer to its left child and a pointer to its right child."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expressed-laptop",
   "metadata": {},
   "source": [
    "A binary tree is not an ordered tree by definition, so the time complexity of common operations is the same as that of a normal tree.\n",
    "\n",
    "There are, however, a lot of different implementations of Binary Trees that make them more efficient in those common operations:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arctic-consequence",
   "metadata": {},
   "source": [
    "<div id=\"binarySearchTrees\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unauthorized-latitude",
   "metadata": {},
   "source": [
    "#### Binary Search Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "circular-charity",
   "metadata": {},
   "source": [
    "Binary Search Trees (BST) are Binary Trees in which the left child of a node (and all of its children) have a value smaller than that of the parent node and the right child of a node (and all of its children) have a value bigger than that of the parent node."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "russian-museum",
   "metadata": {},
   "source": [
    "<figure>\n",
    "    <img src=\"pics/BST.png\" alt=\"Representation of a binary search tree\" width=\"400\"/>\n",
    "    <figcaption>\n",
    "        Binary Tree. Image source: <a href=\"https://www.geeksforgeeks.org/binary-search-tree-data-structure/\">GeeksforGeeks</a>\n",
    "    </figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "split-airline",
   "metadata": {},
   "source": [
    "Analysis of common operations on BSTs:\n",
    "\n",
    "- Search / Access:\n",
    "    \n",
    "    Binary Search Trees are not indexed data structure, so to access an element we need to search for it. BSTs are ordered data structures that work really well with the Binary Search algorithm (an analysis of this algorithm can be found in the algorithms part of this portfolio). Because of the fact that we can use Binary Search with this data structure, we can find an element with a time complexity of $O(h)$, where $h$ is also the height of the tree;\n",
    "    \n",
    "- Insertion:\n",
    "    \n",
    "    Inserting a Node in a BST may require us to change the order of all the other nodes, so in the worst case scenario the time complexity of this operation will be $O(n)$, but in the average case the time complexity of this operation will depend on the height of the tree, so $Θ(h)$;\n",
    "- Deletion:\n",
    "\n",
    "    Deleting a Node has the same impact as inserting a Node. the time complexity of this operation will therefore be $Θ(h)$ in the average case and $O(n)$ in the worst.\n",
    "    \n",
    "An implementation of a BST could be using it together with a binary search algorithm.\n",
    "\n",
    "The main problems with BSTs is that they can be unbalanced when the nodes skew to one of the sides of the tree. In that case the height of the tree is $n$ and the operations in the tree become inefficient. To avoid this and have an height of $log(n)$ we can use a self balancing Binary Tree."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "skilled-technician",
   "metadata": {},
   "source": [
    "<div id=\"redBlackTrees\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "maritime-morrison",
   "metadata": {},
   "source": [
    "#### Red-Black Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wicked-consumption",
   "metadata": {},
   "source": [
    "Red-Black trees are a common kind of self-balancing Binary Trees in which: \n",
    "- Each node has a color property (either red or black); \n",
    "- The root is always black; \n",
    "- A Node cannot have the parent or children of its the same color, except if one or both of its children are leaves; \n",
    "- Its leaves have a null value and are considered black; \n",
    "- And in every path from a node to any of its null descendants contains the same number of black nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooked-vienna",
   "metadata": {},
   "source": [
    "<figure>\n",
    "    <img src=\"pics/RedBlack.png\" alt=\"Representation of a red black tree\" width=\"500\"/>\n",
    "    <figcaption>\n",
    "        Red Black Tree. Image source: <a href=\"https://en.wikipedia.org/wiki/Red–black_tree#/media/File:Red-black_tree_example.svg\">Wikipedia</a>\n",
    "    </figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tracked-lucas",
   "metadata": {},
   "source": [
    "Analysis of common operations on Red-Black Trees:\n",
    "\n",
    "- Search / Access:\n",
    "    \n",
    "    It is possible to perform a Binary Search on a Red-Black Tree, which as we have seen before allows us to search an element with a time complexity of $O(h)$. Since Red-Black trees are a balanced data structure, $h$ will be $log(n)$ and therefore this operation will happen with a time complexity of $O(log(n))$;\n",
    "    \n",
    "- Insertion:\n",
    "    \n",
    "    Since a Red Black Tree is a balanced Tree, and the insertion operation depends on the height of the tree, we can say that this operation will have a worst-case time complexity of $O(log(n))$;\n",
    "- Deletion:\n",
    "\n",
    "    Deleting a node can have the same impact as inserting a node, and this operation depends on the height of the Tree too. Since the height of a Red Black tree is $O(log(n))$, this operation will have a time complexity of $O(log(n))$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proprietary-burden",
   "metadata": {},
   "source": [
    "<div id=\"ropes\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alleged-thomson",
   "metadata": {},
   "source": [
    "#### Ropes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optical-spectacular",
   "metadata": {},
   "source": [
    "A Rope is a Binary Tree used for string manipulation. In a rope, each leaf holds a substring and each inner node the total length of the substrings that are descendants of its left child.\n",
    "\n",
    "In the example below, the root node has as value the total length of the string, which is not a mandatory feature but can be useful in common operations, as we will see below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atomic-toronto",
   "metadata": {},
   "source": [
    "<figure>\n",
    "    <img src=\"pics/Rope.jpg\" alt=\"Representation of a rope\" width=\"500\"/>\n",
    "    <figcaption>\n",
    "        Rope. Image source: <a href=\"https://www.geeksforgeeks.org/ropes-data-structure-fast-string-concatenation/\">GeeksForGeeks</a>\n",
    "    </figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heated-strategy",
   "metadata": {},
   "source": [
    "Common operations that can be done on a rope are different than those done on other trees. These operations include:\n",
    "\n",
    "- Index:\n",
    "\n",
    "    Searching an element by their index is a very common operation in string manipulation, and thanks to the value of the inner nodes this operation can be done on Ropes with time complexity of $O(log(n))$. \n",
    "    \n",
    "    To understand how that is possible let's consider an example, finding the character with at the position i=8 in the example above. We start by comparing i to the value of the root (which in this case holds the value of the total length), and we quickly determine if the index is part of the string. Since is smaller than the value of A, we move to A's left child (B). we compare i to the value of B and since 8 is smaller than 9 we move to B's left child. We compare i to the value of C (6) and since 8 is bigger, we move to  C's right child (F) and since we're moving to the right we update i to b i-C (8-6 = 2), and since F is a leaf we access the child at position i (which is now 2) of the substring (y), which is the 8th character of the whole string.\n",
    "\n",
    "- Concat\n",
    "\n",
    "    To concatenate 2 Ropes we just need to assign them to a new common root node with the value equal to the sum of the length of the substrings that descend from its new left child. This operation can be made in $O(1)$ time complexity, but computing the value for the new root node is an operation that has a time complexity of $O(log(n))$;\n",
    "\n",
    "- Split\n",
    "\n",
    "    When splitting a string starting from an index we need to make a distinction between 2 major cases: we need to start splitting after the last character of a leaf, or we need to start splitting starting from a middle character of a leaf. If our case is the latter, we assign 2 children to the leaf (which becomes an inner node), the left one containing the character that we don't need to split, and the right one containing the characters that we need to split. \n",
    "    \n",
    "    After finding the leaf from which we need to split the Rope, we separate the nodes at the right of that leaf and we fix the weight of the inner nodes that were ancestors of the nodes we separated. We then assign the split nodes to a new common root node.\n",
    "    \n",
    "    At this point, it may be necessary to rebalance both Ropes. \n",
    "    \n",
    "    This operation has a time complexity of $O(log(n))$ since it is the sum of the time complexities of the operations that are needed to complete this operation;\n",
    "\n",
    "- Insert\n",
    "\n",
    "    Inserting a Rope in the middle of another Rope is an operation that can be done by splitting the original Rope, concatenate the Rope we need to insert, and then concatenate the right part of the node we originally split. Rebalancing the tree may be also required. The time complexity of this operation will be the sum of the time complexities of 1 split operation and 2 concatenation operations $(O(log(n))$;\n",
    "\n",
    "- Delete\n",
    "\n",
    "    To delete a substring at the middle of a Rope, we need to split the original rope starting at the first character that we want to delete. We then split the resulting right Rope starting after the last character that we need to delete, and we finally concatenate the left rope of the first split operation with the right Rope of the last split operation. This operation will also have a time complexity given by the sum of the operations that it uses, which will result in a time complexity of $O(n)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "american-provincial",
   "metadata": {},
   "source": [
    "Ropes are widely used in text editors and email clients because of their performances in managing strings, especially compared with a traditional string implement with an array of characters that also requires continuos memory allocation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forbidden-artist",
   "metadata": {},
   "source": [
    "<div id=\"heaps\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demonstrated-evolution",
   "metadata": {},
   "source": [
    "### Heaps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secret-insurance",
   "metadata": {},
   "source": [
    "Heaps are trees in which the parent node always stores a value smaller than that of its children (in the case of a Min Heap) or bigger than that of its children (in case of a Max Heap). In this way the root node always stores the smallest value (in a Min Heap) or the biggest value (in a Max Heap).\n",
    "\n",
    "Heaps do not need to be Binary Trees, but they need to be complete (every level should have the maximum amount of nodes) andif they are not, new elements are added to the incomplete lavel from left to right. Because of this last property, Heaps are usually stored as arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spectacular-wiring",
   "metadata": {},
   "source": [
    "<figure>\n",
    "    <img src=\"pics/Heap.png\" alt=\"Representation of a heap\" width=\"500\"/>\n",
    "    <figcaption>\n",
    "        Heap. Image source: <a href=\"https://www.geeksforgeeks.org/heap-data-structure\">GeeksForGeeks</a>\n",
    "    </figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extra-jefferson",
   "metadata": {},
   "source": [
    "Analysis of common operations on Heaps:\n",
    "\n",
    "- Search / Access:\n",
    "\n",
    "    Searching an element that is not the root node (the node with the max value in a Max Heap or the node with a min value in a Min Heap), we may need to search through all the nodes to find the one we're looking for. Because of this, this operation will have a time complexity of $O(n)$;\n",
    "- Insertion:\n",
    "    \n",
    "    \n",
    "   To insert an element in its correct position in a Heap we need to start by appending it to the last level, which can be done with an average time complexity of $O(1)$ (if the heap is stored in an array). We then need to switch it with its parent node (in case the parent node is smaller and our heap is a Max Heap or in case the parent node is bigger and our Heap is a Min Heap) until it satisfies the properties of the heap. This second operation has a time complexity of $O(log(n))$;\n",
    "- Deletion:\n",
    "   \n",
    "   \n",
    "   To delete an element from a Heap we may also need to rearrange its nodes until the properties of the heap are satisfied. To do this we may need to switch an element for every level of the Heap and since the number of levels is given by $log(n)$ the time complexity of this operation will be $O(log(n))$.\n",
    "   \n",
    "Heaps are used as an auxiliary data structure in various algorithm, like the Heapsort algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adequate-prophet",
   "metadata": {},
   "source": [
    "<div id=\"graphs\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protected-transformation",
   "metadata": {},
   "source": [
    "## Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specialized-drain",
   "metadata": {},
   "source": [
    "Graphs are non-linear data structures made of vertices (or nodes) that store data and edges (that can also store data). Graphs are used to represent the relationships between its nodes or vertices. We have already examined a subset of Graphs, Trees."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electric-ultimate",
   "metadata": {},
   "source": [
    "<figure>\n",
    "    <img src=\"pics/Graph.png\" alt=\"Representation of a graph\" width=\"500\"/>\n",
    "    <figcaption>\n",
    "        Graph. Image source: <a href=\"https://www.geeksforgeeks.org/graph-data-structure-and-algorithms/\">GeeksForGeeks</a>\n",
    "    </figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cutting-somerset",
   "metadata": {},
   "source": [
    "Graphs terminology:\n",
    "\n",
    "- **Vertex** (or Node), an element of the graph that always contains some data;\n",
    "- **Edge**, the relationship between 2 vertices, can also contain information;\n",
    "- **Adjacency**, two nodes connected via an edge;\n",
    "- **Path**, a sequence of edges between 2 vertices;\n",
    "- **Eulerian Path**, a path that visits every edge once (but can visit vertices more than once) and ends up in a vertex which is not the starting one;\n",
    "- **Eulerian Cycle**: a path that visits every edge once (but can visit vertices more than once) and ends up in the starting vertex;\n",
    "- **Hamiltonian Path**, a path that visits every vertex only once (but can visit edges more than once) and ends up in a vertex which is not the starting one;\n",
    "- **Hamiltonina Cycle**: a path that visits every vertex only once (but can visit edges more than once) and ends up in the starting vertex;\n",
    "- **Parallel Edges**, two or more edges that connect the same vertices;\n",
    "- **Loop**, an edge that connect a node to itself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wanted-transfer",
   "metadata": {},
   "source": [
    "Types of Graphs:\n",
    "\n",
    "- **Finite**. A finite Graph contains a finite number of edges and vertices;\n",
    "- **Infinite**. An infinite Graph contains an infinite number of vertices and edges;\n",
    "- **Trivial**. A trivial Graph contains only one vertex and no edges;\n",
    "- **Simple**. A simple Graph contains only one edge between a pair of vertices;\n",
    "- **Non Simple**. A non simple Graph contains more than one edge between a pair of vertices;\n",
    "- **Multi-Graph**. A multi-graph contains some parallel edges but no loops;\n",
    "- **Pseudo-Graph**. a pseudo-graph is a graph with at least a loop and a parallel edge;\n",
    "- **Null**. A null graph contains vertices but no edges;\n",
    "- **Complete** (or Full Graph). In a complete graph every vertex is adjacent to all the others;\n",
    "- **Unweighted**. In an unweighted graph the edges do not store data;\n",
    "- **Weighted**. In a weighted graph the edges store data;\n",
    "- **Directed**. In a directed graph the edges connect 2 vertices only in one direction;\n",
    "- **Undirected**. In an undirected graph the edges connect 2 vertices in both directions;\n",
    "- **Topological**. In a Topological Graphs, the vertices are represented by distinct points in space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "urban-jersey",
   "metadata": {},
   "source": [
    "Ways of representing a graph:\n",
    "\n",
    "- **Adjacency List:**\n",
    "\n",
    "    With an Adjacency List, we use an array to store information about the graph. In a Adjacency List, the array element with the same index as the id of a vertex contains information about its adjacent vertices. An Adjacency List for the graph in the image above will look like this: ```[[1,4],[0,2,3,4],[1,3],[1,2,4],[0,1,3]]```.\n",
    "    \n",
    "    Analysis of common operations on Adjacency Lists:\n",
    "    \n",
    "    - Storage:\n",
    "    \n",
    "        Storing a graph as an Adjacency List can be done with a time complexity of $O(|V| + |E|)$, where $V$ is the number of vertices and also the length of the array, and $E$ is the number of edges;\n",
    "        \n",
    "    - Add Vertex:\n",
    "    \n",
    "        Adding a vertex to a graph represented as an Adjacency List can be done with a time complexity of $O(1)$ since we just need to store a new element to the list;\n",
    "    \n",
    "    - Add Edge:\n",
    "    \n",
    "        Adding an edge to a graph represented as an Adjacency List can be done with a time complexity of $O(1)$, since we just need to add to the arrays representing the two nodes 1 value;\n",
    "    \n",
    "    - Remove Vertex:\n",
    "    \n",
    "        Removing a vertex from a graph represented as an Adjacency List can be done with a time complexity of $O(|V|+|E|)$, since we need to remove the edges to that vertex from all the other vertices as well;\n",
    "    \n",
    "    - Remove Edge:\n",
    "    \n",
    "        Removing an edge from a graph represented as an Adjacency List can be done with a time complexity of $O(|E|)$, since we need to search and remove the edge from the list of edges of the two nodes that it connects.\n",
    "    \n",
    "    \n",
    "    The space complexity of an Adjacency List is $O(|V|+|E|)$.\n",
    "    \n",
    "    \n",
    "- **Adjacency Matrix:**\n",
    "\n",
    "    With an Adjacency Matrix, we use a 2D matrix to store information about the graph. In a Adjacency Matrix, the array element with the same index as the id of a vertex contains an array that indicates if a vertex is connected to another or not (1 if it is, 0 if it is not). An Adjacency Matrix for the graph in the image above will look like this:\n",
    "    \n",
    "    ```\n",
    "    [\n",
    "    [0,1,0,0,1],\n",
    "    [1,0,1,1,1],\n",
    "    [0,1,0,1,0],\n",
    "    [0,1,1,0,1],\n",
    "    [1,1,0,1,0]\n",
    "    ]\n",
    "    ```\n",
    "    \n",
    "    Analysis of common operations on Adjacency Matrices:\n",
    "    \n",
    "    - Storage:\n",
    "    \n",
    "        Storing a graph as an Adjacency matrix can be done with a time complexity of $O(|V|^{2})$, where $V$ is the number of vertices, the number of arrays in te matrix, and the length of each array;\n",
    "\n",
    "    - Add Vertex:\n",
    "    \n",
    "        Adding a vertex to a graph represented as an Adjacency Matrix can be done with a time complexity of $O(|V|^{2})$ since we need to update all the arrays of which the matrix is made up as well as adding a new array;\n",
    "        \n",
    "    - Add Edge:\n",
    "        \n",
    "        Adding an edge to a graph represented as an Adjacency Matrix can be done with a time complexity of $O(1)$, since we just need to add to the update 2 values in the matrix;\n",
    "   \n",
    "    - Remove Vertex:\n",
    "    \n",
    "        Removing a vertex from a graph represented as an Adjacency Matrix can be done with a time complexity of $O(|V|^{2})$, because we need to update all the other arrays of which the matrix is made up;\n",
    "\n",
    "    - Remove Edge:\n",
    "    \n",
    "        Removing an edge from a graph represented as an Adjacency Matrix can be done with a time complexity of $O(1)$, since we need to just update 2 values in the matrix.\n",
    "        \n",
    "    The space complexity of an Adjacency Matrix is $O(|V|^{2})$.\n",
    "\n",
    "\n",
    "Because of their space complexity, it makes sense to use Adjacency Matrices either for small Graphs or Graphs with a lot of edges.\n",
    "\n",
    "One of the possible real world applications of Graphs is for road maps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eight-strategy",
   "metadata": {},
   "source": [
    "<div id=\"sources\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crucial-secretary",
   "metadata": {},
   "source": [
    "# Sources\n",
    "- [Udacity - Data Structures & Algorithms in Python](https://classroom.udacity.com/courses/ud513)\n",
    "- [Cambridge Dictionary - Algorithm](https://dictionary.cambridge.org/dictionary/english/algorithm)\n",
    "- [GeeksforGeeks - Space Complexity](https://www.geeksforgeeks.org/g-fact-86/)\n",
    "- [Khan Academy - Asymptotic Notation](https://www.khanacademy.org/computing/computer-science/algorithms/asymptotic-notation/a/asymptotic-notation)\n",
    "- [The Lean Blogs - Some common runtime complexities and their meanings](https://medium.com/learn-with-the-lean-programmer/some-common-runtime-complexities-and-their-meanings-5a2bf4320f48)\n",
    "- [GeeksforGeeks - Array](https://www.geeksforgeeks.org/array-data-structure/)\n",
    "- [GeeksforGeeks - Linked Lists](https://www.geeksforgeeks.org/data-structures/linked-list/)\n",
    "- [GeeksforGeeks - Doubly Linked Lists](https://www.geeksforgeeks.org/doubly-linked-list/)\n",
    "- [GeeksforGeeks - Stacks](https://www.geeksforgeeks.org/stack-data-structure/)\n",
    "- [GeeksforGeeks - Queues](https://www.geeksforgeeks.org/queue-data-structure/)\n",
    "- [CS Dojo - Hash Tables](https://www.youtube.com/watch?v=sfWyugl4JWA&list=PLBZBJbE_rGRV8D7XZ08LK6z-4zPoWzu5H&index=13)\n",
    "- [Ananda Gunawardena - CMU - Hash Table Conflict Resolution](http://www.cs.cmu.edu/~ab/15-121N11/lectures/lecture16.pdf)\n",
    "- [Typeocaml - Height, Depth and Level of a Tree](http://typeocaml.com/2014/11/26/height-depth-and-level-of-a-tree/)\n",
    "- [GeeksforGeeks - Red-Black Trees](https://www.geeksforgeeks.org/red-black-tree-set-1-introduction-2/)\n",
    "- [GeeksforGeeks - Ropes](https://www.geeksforgeeks.org/ropes-data-structure-fast-string-concatenation/)\n",
    "- [Opengenus - Ropes](https://iq.opengenus.org/rope-data-structure/)\n",
    "- [GeeksforGeeks - Heaps](https://www.geeksforgeeks.org/heap-data-structure/)\n",
    "- [HackerRank - Heaps](https://www.youtube.com/watch?v=t0Cq6tVNRBA)\n",
    "- [Tutorialspoint - Graphs](https://www.tutorialspoint.com/data_structures_algorithms/graph_data_structure.htm)\n",
    "- [GeeksforGeeks - Types of Graphs](https://www.geeksforgeeks.org/graph-types-and-applications/)\n",
    "- [BigO complexities [pdf]](http://souravsengupta.com/cds2016/lectures/Complexity_Cheatsheet.pdf)\n",
    "- Skiena, S. The Algorithm Design Manual. 1998. Springer."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
